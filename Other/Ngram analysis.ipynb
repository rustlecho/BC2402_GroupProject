{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5eebacfe-3394-4c74-9e30-ea4d974597f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "import pymongo\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d5f28ec1-da63-466f-b3a2-03502914dd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "952fbdaf-0489-45c5-bcf3-cd0f1cdb0557",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"grp_proj\"]\n",
    "collection = db[\"cleaned_reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fd61b587-9c50-40ae-b6e6-30a09169486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ngram for Common Complaints\n",
    "titles = collection.find({\"complaints\":\"yes\"}, {\"Title\": 1, \"_id\": 0})\n",
    "ngrams_list = []\n",
    "stop_words = set(stopwords.words('english'))  # Stop words set\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "for title in titles:\n",
    "    text = title.get(\"Title\", \"\").lower()\n",
    "    tokens = text.split()  # Tokenize the text\n",
    "    filtered_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    n_grams = ngrams(tokens, 2)  # Change 2 to 3 for trigrams\n",
    "    ngrams_list.extend(n_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "09eb4d62-35b3-4cad-a2ff-c494f4ac476d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('food', 'was'), 15), (('qatar', 'airways'), 15), (('singapore', 'airlines'), 14), (('the', 'food'), 11), (('seats', 'were'), 10), (('for', 'the'), 10), (('very', 'poor'), 9), (('was', 'not'), 9), (('to', 'be'), 9), (('seat', 'was'), 8), (('customer', 'service'), 8), (('was', 'very'), 8), (('business', 'class'), 8), (('the', 'service'), 8), (('i', 'was'), 8), (('service', 'was'), 8), (('thank', 'you'), 8), (('my', 'seat'), 8), (('this', 'airline'), 7), (('the', 'crew'), 7), (('the', 'worst'), 7), (('on', 'the'), 7), (('cabin', 'crew'), 7), (('up', 'to'), 7), (('quality', 'of'), 7), (('customer', 'review'), 7), (('service', 'is'), 6), (('is', 'a'), 6), (('my', 'luggage'), 6), (('to', 'the'), 6), (('did', 'not'), 6), (('it', 'was'), 6), (('premium', 'economy'), 6), (('meals', 'were'), 6), (('seats', 'are'), 6), (('of', 'service'), 6), (('this', 'flight'), 6), (('above', 'and'), 5), (('and', 'beyond'), 5), (('service', 'and'), 5), (('was', 'a'), 5), (('flight', 'was'), 5), (('airlines', 'customer'), 5), (('my', 'flight'), 5), (('the', 'flight'), 5), (('disappointed', 'with'), 5), (('the', 'seat'), 5), (('a', 'little'), 5), (('by', 'the'), 5), (('all', 'the'), 5), (('seat', 'is'), 4), (('in', 'the'), 4), (('for', 'a'), 4), (('the', 'meals'), 4), (('me', 'a'), 4), (('recommend', 'this'), 4), (('the', 'refund'), 4), (('was', 'terrible'), 4), (('from', 'the'), 4), (('has', 'been'), 4), (('to', 'get'), 4), (('a', 'refund'), 4), (('not', 'comfortable'), 4), (('out', 'of'), 4), (('crew', 'were'), 4), (('was', 'the'), 4), (('staff', 'were'), 4), (('exit', 'row'), 4), (('fly', 'with'), 3), (('with', 'them'), 3), (('poor', 'service'), 3), (('refused', 'to'), 3), (('i', 'recommend'), 3), (('found', 'the'), 3), (('the', 'seats'), 3), (('second', 'to'), 3), (('to', 'none'), 3), (('and', 'uncomfortable'), 3), (('should', 'have'), 3), (('cost', 'cutting'), 3), (('the', 'quality'), 3), (('offer', 'me'), 3), (('me', 'any'), 3), (('there', 'was'), 3), (('is', 'not'), 3), (('a', 'very'), 3), (('very', 'average'), 3), (('very', 'disappointed'), 3), (('in', 'service'), 3), (('meal', 'was'), 3), (('cancelled', 'my'), 3), (('crew', 'seemed'), 3), (('food', 'and'), 3), (('service', 'has'), 3), (('waiting', 'for'), 3), (('trying', 'to'), 3), (('with', 'the'), 3), (('wanted', 'to'), 3), (('big', 'thank'), 3), (('not', 'allowed'), 3)]\n"
     ]
    }
   ],
   "source": [
    "ngram_freq = Counter(ngrams_list)\n",
    "print(ngram_freq.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d8dd9b52-8893-4fb1-a3fc-ef6d519add3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ngram for issues during exceptional circumstances\n",
    "titles = collection.find({\"complaints\":\"yes\",\"exceptional\":True}, {\"Title\": 1, \"_id\": 0})\n",
    "ngrams_list = []\n",
    "stop_words = set(stopwords.words('english'))  # Stop words set\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "for title in titles:\n",
    "    text = title.get(\"Title\", \"\").lower()\n",
    "    tokens = text.split()  # Tokenize the text\n",
    "    filtered_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    n_grams = ngrams(tokens, 2)  # Change 2 to 3 for trigrams\n",
    "    ngrams_list.extend(n_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d0258151-bd41-4b9b-b296-7df7209ad09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('singapore', 'airlines'), 4), (('it', 'was'), 4), (('service', 'was'), 4), (('the', 'food'), 3), (('food', 'was'), 3), (('was', 'a'), 3), (('crew', 'seemed'), 3), (('to', 'be'), 3), (('fly', 'with'), 2), (('the', 'seats'), 2), (('for', 'the'), 2), (('up', 'to'), 2), (('offer', 'me'), 2), (('was', 'not'), 2), (('we', 'were'), 2), (('usual', 'high'), 2), (('flight', 'was'), 2), (('seemed', 'to'), 2), (('the', 'change'), 2), (('i', 'recommend'), 2), (('lack', 'of'), 2), (('to', 'premium'), 2), (('premium', 'economy'), 2), (('an', 'experience'), 2), (('experience', 'onboard'), 2), (('meals', 'were'), 2), (('left', 'me'), 1), (('me', 'deeply'), 1), (('deeply', 'disappointed'), 1), (('not', 'fly'), 1), (('with', 'them'), 1), (('them', 'in'), 1), (('in', 'the'), 1), (('the', 'future'), 1), (('flight', 'delayed'), 1), (('delayed', 'almost'), 1), (('almost', '4'), 1), (('4', 'hours'), 1), (('no', 'inflight'), 1), (('inflight', 'entertainment'), 1), (('entertainment', 'at'), 1), (('at', 'all'), 1), (('they', 'have'), 1), (('have', 'not'), 1), (('not', 'followed'), 1), (('followed', 'through'), 1), (('not', 'the'), 1), (('the', 'singapore'), 1), (('airlines', 'i'), 1), (('i', 'know!'), 1), (('sq', 'has'), 1), (('has', 'not'), 1), (('not', 'provided'), 1), (('provided', 'any'), 1), (('any', 'explanation'), 1), (('i', 'found'), 1), (('found', 'the'), 1), (('seats', 'a'), 1), (('a', 'bit'), 1), (('bit', 'uncomfortable'), 1), (('compensation', 'should'), 1), (('should', 'have'), 1), (('have', 'been'), 1), (('been', 'upgrade'), 1), (('50', 'minutes'), 1), (('minutes', 'for'), 1), (('the', 'priority'), 1), (('priority', 'baggage'), 1), (('late', 'by'), 1), (('by', 'up'), 1), (('to', '90'), 1), (('90', 'mins'), 1), (('refused', 'to'), 1), (('to', 'offer'), 1), (('me', 'any'), 1), (('any', 'compensation'), 1), (('not', 'good'), 1), (('were', 'disappointed'), 1), (('did', 'not'), 1), (('not', 'offer'), 1), (('offer', 'toiletries'), 1), (('toiletries', 'pack'), 1), (('to', 'their'), 1), (('their', 'usual'), 1), (('high', 'standards'), 1), (('were', '4'), 1), (('4', 'minutes'), 1), (('minutes', 'late'), 1), (('miss', 'pre-pandemic'), 1), (('pre-pandemic', 'singapore'), 1), (('a', 'very'), 1), (('very', 'average'), 1), (('average', 'experience'), 1), (('a', '5/10'), 1), (('5/10', 'flight'), 1), (('a', 'good'), 1), (('good', 'flight'), 1), (('was', 'spoiled'), 1), (('spoiled', 'by'), 1), (('by', 'an'), 1)]\n"
     ]
    }
   ],
   "source": [
    "ngram_freq = Counter(ngrams_list)\n",
    "print(ngram_freq.most_common(100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
